import random
from abc import ABC
from typing import List, Dict, Optional
from ale.config import NLPTask
from ale.corpus.corpus import Corpus
from ale.registry.registerable_teacher import TeacherRegistry
from ale.teacher.base_teacher import BaseTeacher
from ale.teacher.exploitation.aggregation_methods import AggregationMethod
from ale.trainer.predictor import Predictor
from ale.trainer.prediction_result import TokenConfidence, PredictionResult


class HistoricalDoc:
    def __init__(self, idx: int, confidence: float, window_size: int) -> None:
        """
        Helper class used to save confidence scores of last cycles for one document.
        """
        self.idx: int = idx
        self.historical_confidences: List[float] = [confidence]
        self.window_size: int = window_size

    def update_confidences(self, confidence: float) -> List[float]:
        """
        Appends the new confidence scores to the historical confidence list.

        Args:
            - confidence (float): confidence score of current cycle for document
        Returns:
            - scores (List[float]): the updated list of confidence scores for last window-size cycles
        """
        self.historical_confidences.append(confidence)
        return self.get_confidences_for_window()

    def get_confidences_for_window(self, window_size: Optional[int] = None) -> List[float]:
        if window_size is None:
            window_size = self.window_size
        return self.historical_confidences[-window_size:]


class HistoricalSequence:
    def __init__(self, docs_with_predictions: Dict[int, float], window_size: int) -> None:
        """
        Helper class used to wrap predictions of last cycle.

        Args:
            - docs_with_predictions (Dict[int,float]): Dict containing the ids of the documents and
                                                       their predicted confidence score
            - window_size (int): the number of historical sequences to calculate the score
        """
        self.window_size = window_size
        self.docs: Dict[int, HistoricalDoc] = {}
        for doc_idx, confidence_score in docs_with_predictions.items():
            self.docs[doc_idx] = HistoricalDoc(doc_idx, confidence_score, self.window_size)

    def update_and_get_historical_sequences(self, docs_with_predictions: Dict[int, float]) -> Dict[int, List[float]]:
        historical_sequences: Dict[int, List[float]] = {}
        for doc in docs_with_predictions:
            historical_doc: Optional[HistoricalDoc] = self.get_historical_doc_by_id(doc)
            if historical_doc:  # history exists for document
                sequence: List[float] = historical_doc.update_confidences(docs_with_predictions[doc])
                historical_sequences[doc] = sequence
            else:
                historical_doc: HistoricalDoc = HistoricalDoc(doc, docs_with_predictions[doc], self.window_size)
                sequence: List[float] = historical_doc.get_confidences_for_window()
                historical_sequences[doc] = sequence
        return historical_sequences

    def get_historical_doc_by_id(self, idx: int) -> Optional[HistoricalDoc]:
        if idx not in self.docs:
            return None

        return self.docs[idx]


@TeacherRegistry.register("fluctuation-historical-sequence")
class FluctuationHistoricalSequenceTeacher(BaseTeacher, ABC):
    """
    Fluctuation Historical Sequence teacher using LC: chooses documents with the highest fluctuation in last n cycles
    Should be used for initial train as well to save predictions already for initial train.

        Applied to ER task: 
        - Yao, J., Dou, Z., Nie, J., Wen, J.: Looking Back on the Past: Active Learning with Historical Evaluation Results. 
        IEEE Transactions on Knowledge and Data Engineering (2020). https://doi.org/10.1109/TKDE.2020.3045816
    """

    def __init__(
            self,
            corpus: Corpus,
            predictor: Predictor,
            seed: int,
            labels: List[any],
            nlp_task: NLPTask,
            aggregation_method: Optional[AggregationMethod],
            historical_window_size: Optional[int] = 3,  # recommendation of authors (Yao (2020))
            weight: Optional[float] = 0.5  # recommendation of authors (Yao (2020))
    ):
        super().__init__(
            corpus=corpus,
            predictor=predictor,
            seed=seed,
            labels=labels,
            nlp_task=nlp_task,
            aggregation_method=aggregation_method
        )
        random.seed(self.seed)
        self.historical_sequence: Optional[HistoricalSequence] = None
        self.historical_window_size: int = historical_window_size
        self.weight: float = weight

    def propose(self, potential_ids: List[int], step_size: int, budget: int) -> List[int]:
        search_for_least_confidence = random.sample(potential_ids, budget)
        idx2text = self.corpus.get_text_by_ids(search_for_least_confidence)
        prediction_results: Dict[int, PredictionResult] = self.predictor.predict(idx2text)
        out_ids: List[int] = self.compute_function(prediction_results, step_size)

        return out_ids

    def compute_ner(self, predictions: Dict[int, PredictionResult], step_size: int) -> List[int]:
        """
        Fluctuation of Historical Sequence is calculated on instance-level,
        LC is used with token-score, aggregated as configured.
        """
        if self.is_initial_train():  # TODO Question: Do we have a model at this point?
            next_batch = random.sample(list(predictions.keys()), step_size)
            instance_scores: Dict[int, float] = self.compute_least_confidence_instance_scores(predictions)
            self.historical_sequence: HistoricalSequence = HistoricalSequence(instance_scores,
                                                                              self.historical_window_size)
            return next_batch  # TODO Question: returning the random batch for comparison reason?

        instance_scores: Dict[int, float] = self.compute_least_confidence_instance_scores(predictions)
        historical_sequences: Dict[int, List[float]] = self.historical_sequence.update_and_get_historical_sequences(
            instance_scores)

        fluctuation_scores: Dict[int, float] = self.compute_fluctuation_scores_per_doc(historical_sequences)

        # LC calculated with 1-highest score, therefore take max
        sorted_dict_by_score = sorted(fluctuation_scores.items(), key=lambda x: x[1], reverse=True)
        out_ids = [item[0] for item in sorted_dict_by_score[:step_size]]

        return out_ids

    def compute_fluctuation_scores_per_doc(self, historical_sequences) -> Dict[int, float]:
        fluctuation_scores: Dict[int, float] = dict()
        for idx, hist_scores in historical_sequences.items():
            fluctuation_scores[idx] = self.compute_fhs_score(hist_scores)
        return fluctuation_scores

    def compute_fhs_score(self, hist_scores: List[float]) -> float:
        weight = self.weight  # in paper (11) referred as w_s
        fluctuation = self.compute_fluctuation(hist_scores)
        # balances score between current least confidence and historical information using weight
        total_score: float = weight * hist_scores[-1] + (1 - weight) * fluctuation
        return total_score

    def compute_fluctuation(self, hist_scores: List[float]) -> float:
        length = len(hist_scores)  # in paper (11) referred as l
        inner_value = [(hist_value - (1 / length) * sum([j for j in hist_scores])) ** 2 for hist_value in hist_scores]
        fluctuation: float = (1 / length) * sum(inner_value)
        return fluctuation

    def compute_least_confidence_instance_scores(self, predictions: Dict[int, PredictionResult]) -> Dict[int, float]:
        scores = dict()
        for idx, prediction in predictions.items():
            token_confidences: List[TokenConfidence] = prediction.ner_confidences_token
            highest_confidences: List[float] = []
            for token in token_confidences:
                # LC on token-level, reversed to take max  # TODO Question: Why not taking MIN?
                confidence_score: float = 1 - token.get_highest_confidence().confidence
                highest_confidences.append(confidence_score)
            instance_score = self.aggregate_function(highest_confidences)
            scores[idx] = instance_score
        return scores

    def is_initial_train(self) -> bool:
        return self.historical_sequence is None

    def compute_cls(self, predictions: Dict[int, PredictionResult], step_size: int) -> List[int]:
        raise NotImplementedError(
            "Fluctuation Historical Sequence teacher is not implemented for text classification yet.")
