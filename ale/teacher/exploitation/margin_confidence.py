import random
from abc import ABC
from typing import List, Dict, Optional

import numpy as np

from ale.corpus.corpus import Corpus
from ale.registry.registerable_teacher import TeacherRegistry
from ale.teacher.base_teacher import BaseTeacher
from ale.teacher.exploitation.aggregation_methods import AGGREGATION_METHOD
from ale.trainer.base_trainer import Predictor, PredictionResult
from ale.config import NLPTask

@TeacherRegistry.register("margin-confidence")
class MarginTeacher(BaseTeacher, ABC):
    """
    Random teacher: folds the data initially and makes random choices from iterated folds as propose is called
    """

    def __init__(
        self,
        corpus: Corpus,
        predictor: Predictor,
        seed: int,
        labels: List[any],
        nlp_task: str,
        aggregation_method: Optional[AGGREGATION_METHOD]
    ):
        super().__init__(
            corpus=corpus,
            predictor=predictor,
            seed=seed,
            labels=labels,
            nlp_task=nlp_task,
            aggregation_method=aggregation_method
        )
        random.seed(self.seed)

    def propose(self, potential_ids: List[int], step_size: int, budget: int) -> List[int]:        
        search_for_least_confidence = random.sample(potential_ids, budget)
        idx2text = self.corpus.get_text_by_ids(search_for_least_confidence)
        prediction_results: Dict[int,PredictionResult] = self.predictor.predict(idx2text)
        out_ids: List[int] = self.compute_function(prediction_results, step_size)

        return out_ids
    
    def compute_ner(self, predictions: Dict[int,PredictionResult], step_size: int) -> List[int]:
        """
        Margin is calculated on token-level and aggregated on instance-level as configured.
        """
        scores = dict()
        for idx,prediction in predictions.items():
            confidences: Dict[int,List[float]] = prediction.ner_confidences_token
            margins: List[float] = []
            tokens = list(confidences.keys())
            for token in tokens:
                confidence_scores: List[float] = confidences[token]
                sorted_index = np.argsort(confidence_scores)[-2:]
                margin = abs(confidence_scores[sorted_index[0]] - confidence_scores[sorted_index[1]])
                margins.append(margin)
            instance_margin = self.aggregate_function(margins)
            scores[idx] = instance_margin
        sorted_dict_by_score = sorted(scores.items(), key=lambda x:x[1])
        out_ids = [item[0] for item in sorted_dict_by_score[:step_size]]
        
        return out_ids

    def compute_cls(self, predictions: Dict[int,PredictionResult], step_size: int) -> List[int]:
        scores = dict()
        for idx, prediction in predictions.items():
            confidences = np.array(list(prediction.classification_confidences.values()))
            sorted_index = np.argsort(confidences)[-2:]
            diff = abs(confidences[sorted_index[0]] - confidences[sorted_index[1]])
            scores[idx] = diff

        sorted_dict_by_score = sorted(scores.items(), key=lambda x:x[1])
        out_ids = [item[0] for item in sorted_dict_by_score[:step_size]]
        
        return out_ids

