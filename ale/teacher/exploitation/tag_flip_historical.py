import random
from abc import ABC
from typing import List, Dict, Optional
from ale.config import NLPTask
from ale.corpus.corpus import Corpus
from ale.registry.registerable_teacher import TeacherRegistry
from ale.teacher.base_teacher import BaseTeacher
from ale.teacher.exploitation.aggregation_methods import AggregationMethod
from ale.trainer.base_trainer import Predictor, PredictionResult


class HistoricalDoc:
    def __init__(self, idx: int, prediction_result: PredictionResult) -> None:
        """
        Helper class used to save predictions of last cycle for one document.
        """
        self.idx: int = idx
        self.labels: List[str] = [token_confidence.get_predicted_label(
        ) for token_confidence in prediction_result.ner_confidences_token]

    def update_and_compare_labels(self, predictions: PredictionResult) -> List[int]:
        """
        Compares old and new labels and returns a list indicating which label predictions have changed (per token).

        Args:
            - predictions (PredictionResult): prediction result of current cycle

        Returns:
            - difference (List[int]): a list which indicates if the token-predictions has changed (1) or not (0)
        """
        difference: List[int] = []
        labels: List[str] = [token_confidence.get_predicted_label()
                             for token_confidence in predictions.ner_confidences_token]

        if len(labels) != len(self.labels):
            raise AssertionError(
                "Length of label sequence must always be of equal length for one document.")

        for label, old_label in zip(labels, self.labels):
            if label == old_label:
                difference.append(0)  # no tag flip
            else:
                difference.append(1)  # tag flip
        self.labels = labels
        return difference

    def get_labels(self) -> List[str]:
        return self.labels


class HistoricalSequence:
    def __init__(self, docs_with_predictions: Dict[int, PredictionResult]) -> None:
        """
        Helper class used to wrap predictions of last cycle.

        Args:
            - docs_with_predictions (Dict[int,PredictionResult]): Dict containing the ids of the documents and their prediction result
        """
        self.docs: List[HistoricalDoc] = []
        for doc in docs_with_predictions:
            historical_doc: HistoricalDoc = HistoricalDoc(
                doc, docs_with_predictions[doc])
            self.docs.append(historical_doc)

    def update_and_compare_historical_sequences(self, docs_with_predictions: Dict[int, PredictionResult]) -> Dict[int, List[int]]:
        differences: Dict[int, List[int]] = {}
        for doc in docs_with_predictions:
            historical_doc: Optional[HistoricalDoc] = self.get_historical_doc_by_id(
                doc)
            if historical_doc:  # history exists for document
                difference: List[int] = historical_doc.update_and_compare_labels(
                    docs_with_predictions[doc])
                differences[doc] = difference
            else:
                historical_doc: HistoricalDoc = HistoricalDoc(
                    doc, docs_with_predictions[doc])
                # doc never predicted before, so no difference
                difference: List[int] = [
                    0 for item in historical_doc.get_labels()]
                differences[doc] = difference
        return differences

    def get_historical_doc_by_id(self, idx: int) -> Optional[HistoricalDoc]:
        for doc in self.docs:
            if doc.idx == idx:
                return doc
        return None


@TeacherRegistry.register("tag-flip-historical")
class TagFlipTeacher(BaseTeacher, ABC):
    """
    Tag Flip teacher using historical sequences: chooses documents with most tag flips in comparison to last cycle
    Should be used for initial train as well to save predictions already for initial train.

        Applied to ER task:
        - aggregation by sum: 
            - Zheng, G., Mukherjee, S., Dong, X., Li, F.: OpenTag: Open aribute value extraction from product 
            profiles. In: Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and 
            Data Mining. pp. 1049â€“1058 (2018). https://doi.org/10.1145/3219819.3219839
    """

    def __init__(
        self,
        corpus: Corpus,
        predictor: Predictor,
        seed: int,
        labels: List[any],
        nlp_task: NLPTask,
        aggregation_method: Optional[AggregationMethod]
    ):
        super().__init__(
            corpus=corpus,
            predictor=predictor,
            seed=seed,
            labels=labels,
            nlp_task=nlp_task,
            aggregation_method=aggregation_method
        )
        random.seed(self.seed)
        self.historical_sequence = None

    def propose(self, potential_ids: List[int], step_size: int, budget: int) -> List[int]:
        batch = random.sample(potential_ids, budget)
        idx2text = self.corpus.get_text_by_ids(batch)
        prediction_results: Dict[int, PredictionResult] = self.predictor.predict(
            idx2text)
        out_ids: List[int] = self.compute_function(
            prediction_results, step_size)

        return out_ids

    def compute_ner(self, predictions: Dict[int, PredictionResult], step_size: int) -> List[int]:
        """
        Tag Flip is calculated on token-level and aggregated on instance-level as configured.
        """
        scores = dict()

        if not self.historical_sequence:  # initial train
            next_batch = random.sample(list(predictions.keys()), step_size)
            self.historical_sequence: HistoricalSequence = HistoricalSequence(
                predictions)
            return next_batch

        else:  # all other cycles
            differences: Dict[int, List[int]] = self.historical_sequence.update_and_compare_historical_sequences(
                predictions)
            for idx in differences:
                instance_score = self.aggregate_function(differences[idx])
                scores[idx] = instance_score

        sorted_dict_by_score = sorted(
            scores.items(), key=lambda x: x[1], reverse=True)
        out_ids = [item[0] for item in sorted_dict_by_score[:step_size]]

        return out_ids

    def compute_cls(self, predictions: Dict[int, PredictionResult], step_size: int) -> List[int]:
        raise NotImplementedError(
            "Tag Flip teacher is not implemented for text classification yet.")
