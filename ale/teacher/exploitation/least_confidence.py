import random
from abc import ABC
from typing import List, Dict, Optional
from ale.config import NLPTask
from ale.corpus.corpus import Corpus
from ale.registry.registerable_teacher import TeacherRegistry
from ale.teacher.base_teacher import BaseTeacher
from ale.teacher.exploitation.aggregation_methods import AggregationMethod
from ale.trainer.predictor import Predictor
from ale.trainer.prediction_result import TokenConfidence, PredictionResult


@TeacherRegistry.register("least-confidence")
class LeastConfidenceTeacher(BaseTeacher, ABC):
    """
    Least Confidence teacher: chooses documents where the confidence in the most probable label is lowest

        Applied to ER task:
        - aggregation by average: 
            - Esuli, A., Marcheggiani, D., Sebastiani, F.: Sentence-based active learning strategies 
            for information extraction. In: CEUR Workshop Proceedings. vol. 560, pp. 41–45 (2010)
        - aggregation by minimum: 
            - Esuli, A., Marcheggiani, D., Sebastiani, F.: Sentence-based active learning strategies 
            for information extraction. In: CEUR Workshop Proceedings. vol. 560, pp. 41–45 (2010)
        - aggregation by sum: 
            - A.O.B. Şapci et al. “Focusing on Potential Named Entities during Active Label 
            Acquisition”. In: Natural Language Engineering (2023). DOI: 10.1017/S1351324923000165.
            https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162145912&doi=10.1017%2fS1351324923000165&partnerID=40&md5=340e4f2adb01a08f0cf0abd952a63946
            - Linh, L., Nguyen, M.T., Zuccon, G., Demartini, G.: Loss-based Active Learning for
            Named Entity Recognition. In: Proceedings of the International Joint Conference on Neural 
            Networks. vol. 2021-July (2021). https://doi.org/10.1109/IJCNN52387.2021.9533675
        - aggregation by maximum: 
            - Esuli, A., Marcheggiani, D., Sebastiani, F.: Sentence-based active learning strategies 
            for information extraction. In: CEUR Workshop Proceedings. vol. 560, pp. 41–45 (2010)
            - A.O.B. Şapci et al. “Focusing on Potential Named Entities during Active Label 
            Acquisition”. In: Natural Language Engineering (2023). DOI: 10.1017/S1351324923000165.
            https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162145912&doi=10.1017%2fS1351324923000165&partnerID=40&md5=340e4f2adb01a08f0cf0abd952a63946
            - Liu, M., Tu, Z., Zhang, T., Su, T., Xu, X., Wang, Z.: LTP: A New Active Learning Strategy 
            for CRF-Based Named Entity Recognition. Neural Processing Letters 54(3), 2433–2454 (2022). https://doi.org/10.1007/s11063-021-10737-x
            - Li, W., Du, Y., Li, X., Chen, X., Xie, C., Li, H., Li, X.: UD BBC: Named entity 
            recognition in social network combined BERT-BiLSTM-CRF with active learning. 
            Engineering Applications of Artificial Intelligence (2022). https://doi.org/10.1016/j.engappai.2022.105460
        - aggregation by standard deviation:
            -  Claveau, V., Kijak, E.: Strategies to select examples for active learning with conditional 
            random fields. In: Lecture Notes in Computer Science (Including SubseriesLecture Notes in 
            Artificial Intelligence and Lecture Notes in Bioinformatics). vol. 10761 LNCS, pp. 30–43 (2018). https://doi.org/10.1007/978-3-319-77113-7    
    """

    def __init__(
        self,
        corpus: Corpus,
        predictor: Predictor,
        seed: int,
        labels: List[any],
        nlp_task: NLPTask,
        aggregation_method: Optional[AggregationMethod]
    ):
        super().__init__(
            corpus=corpus,
            predictor=predictor,
            seed=seed,
            labels=labels,
            nlp_task=nlp_task,
            aggregation_method=aggregation_method
        )
        random.seed(self.seed)

    def propose(self, potential_ids: List[int], step_size: int, budget: int) -> List[int]:
        search_for_least_confidence = random.sample(potential_ids, budget)
        idx2text = self.corpus.get_text_by_ids(search_for_least_confidence)
        prediction_results: Dict[int, PredictionResult] = self.predictor.predict(
            idx2text)
        out_ids: List[int] = self.compute_function(
            prediction_results, step_size)

        return out_ids

    def compute_ner(self, predictions: Dict[int, PredictionResult], step_size: int) -> List[int]:
        """
        LC is calculated on token-level and aggregated on instance-level as configured.
        """
        scores = dict()
        for idx, prediction in predictions.items():
            token_confidences: List[TokenConfidence] = prediction.ner_confidences_token
            highest_confidences: List[float] = []
            for token in token_confidences:
                confidence_score: float = token.get_highest_confidence().confidence
                highest_confidences.append(confidence_score)
            instance_score = self.aggregate_function(highest_confidences)
            scores[idx] = instance_score
        sorted_dict_by_score = sorted(scores.items(), key=lambda x: x[1])
        out_ids = [item[0] for item in sorted_dict_by_score[:step_size]]

        return out_ids

    def compute_cls(self, predictions: Dict[int, PredictionResult], step_size: int) -> List[int]:
        raise NotImplementedError(
            "Least Confidence teacher is not implemented for text classification yet.")
