import random
from abc import ABC
from typing import List, Dict, Optional
from ale.config import NLPTask
from ale.corpus.corpus import Corpus
from ale.registry.registerable_teacher import TeacherRegistry
from ale.teacher.base_teacher import BaseTeacher
from ale.teacher.exploitation.aggregation_methods import AggregationMethod
from ale.trainer.base_trainer import Predictor, PredictionResult
from ale.trainer.prediction_result import TokenConfidence, LabelConfidence
from ale.teacher.utils import is_named_entity


class LabelScores:
    def __init__(self, idx, label_confidences: Dict[str, float]):
        self.idx = idx
        self.confidences: List[LabelConfidence] = []
        for label, instance_score in label_confidences.items():
            self.confidences.append(LabelConfidence(
                label=label, confidence=instance_score))

    def get_score(self, label: str) -> float:
        for conf in self.confidences:
            if conf.label == label:
                return conf.confidence
        raise ValueError("Given label not in label classes of ER task.")


@TeacherRegistry.register("round-robin-highest-confidence")
class RoundRobinHighestConfidenceTeacher(BaseTeacher, ABC):
    """
    Round Robin Highest Confidence teacher: chooses documents alternating over all label classes with highest confidence for label

        Applied to ER task:
        - aggregation by average: 
            - Esuli, A., Marcheggiani, D., Sebastiani, F.: Sentence-based active learning strategies for 
            information extraction. In: CEUR Workshop Proceedings. vol. 560, pp. 41–45 (2010)
        - aggregation by maximum: 
            - Esuli, A., Marcheggiani, D., Sebastiani, F.: Sentence-based active learning strategies for 
            information extraction. In: CEUR Workshop Proceedings. vol. 560, pp. 41–45 (2010)
    """

    def __init__(
        self,
        corpus: Corpus,
        predictor: Predictor,
        seed: int,
        labels: List[any],
        nlp_task: NLPTask,
        aggregation_method: Optional[AggregationMethod]
    ):
        super().__init__(
            corpus=corpus,
            predictor=predictor,
            seed=seed,
            labels=labels,
            nlp_task=nlp_task,
            aggregation_method=aggregation_method
        )
        random.seed(self.seed)

    def propose(self, potential_ids: List[int], step_size: int, budget: int) -> List[int]:
        batch = random.sample(potential_ids, budget)
        idx2text = self.corpus.get_text_by_ids(batch)
        prediction_results: Dict[int, PredictionResult] = self.predictor.predict(
            idx2text)
        out_ids: List[int] = self.compute_function(
            prediction_results, step_size)

        return out_ids

    def compute_ner(self, predictions: Dict[int, PredictionResult], step_size: int) -> List[int]:
        """
        Max tag count is calculated on token-level and aggregated on instance-level as configured.
        """
        scores: Dict[int, LabelScores] = dict()  # {idx: LabelScore}

        # Get all label classes (without "O") of the ER task
        first_idx: int = next(iter(predictions))
        first_predictions: PredictionResult = predictions.get(first_idx)
        labels: List[str] = first_predictions.get_all_label_classes()

        for idx, prediction in predictions.items():
            # Generate dict with all labels
            label_confs: Dict[str, List[float]] = {}
            for label in labels:
                label_confs[label] = []

            # For each token: Add confidence score for each label to dict
            token_confidences: List[TokenConfidence] = prediction.ner_confidences_token
            for conf in token_confidences:
                for label_conf in conf.label_confidence:
                    if is_named_entity(label_conf.label):
                        label_confs[label_conf.label].append(
                            label_conf.confidence)

            # Generate instance level score for each label class separately
            label_result: Dict[str, str] = {}
            for label, confs in label_confs.items():
                label_result[label] = self.aggregate_function(
                    confs)  # aggregate per label
            scores[idx] = LabelScores(idx, label_result)

        # Get sorted dict with all labels and their best docs in descending order
        # {label: [idx]} in descending order
        label_docs_order: Dict[str, List[int]] = dict()
        for label in labels:
            scores_label = {}
            for idx, doc_label_scores in scores.items():
                doc_label_score: float = doc_label_scores.get_score(label)
                scores_label[idx] = doc_label_score
            sorted_dict_by_score = sorted(
                scores_label.items(), key=lambda x: x[1], reverse=True)
            label_docs_order[label] = [
                doc for doc, score in sorted_dict_by_score]

        # Apply round robin
        robin: int = 0  # Iterate over label classes
        num_labels: int = len(labels)
        out_ids: List[int] = []

        while len(out_ids) < step_size:
            class_idx = robin % num_labels
            cur_label = labels[class_idx]
            for i, doc in enumerate(label_docs_order[cur_label]):
                if doc not in out_ids:  # Check if doc already proposed by other class
                    out_ids.append(doc)
                    # Remove docs that are already in out_ids
                    label_docs_order[cur_label] = label_docs_order[cur_label][i+1:]
                    break
        return out_ids

    def compute_cls(self, predictions: Dict[int, PredictionResult], step_size: int) -> List[int]:
        raise NotImplementedError(
            "Round Robin teacher is not implemented for text classification yet.")
